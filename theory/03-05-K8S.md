Conceptos necesarios para entender k8s:

* **Cluster**: Cuando "desplegamos" con k8s, lo que estamos creando/obteniendo es un cluster. Un cluster no es más que un conjunto de VMs (nodos) que ejecutan aplicaciones contenerizadas. Todo cluster tiene al menos un nodo.

* **Node**: Como hemos comentado, un nodo es una instancia de una VM donde se sirven los contenedores de nuestras aplicaciones
* **Pod**: Un pod es una abstracción de k8s que representa un conjunto de contenedores que son servidos en un nodo
* **Control plane**: Se refiere a la capa de orquestación que expone la API e interfaces para definir, desplegar, y gestionar el ciclo de vida de los contenedores. En un entorno productivo, el **control plane** suele estar corriendo en varios nodos, lo que garantiza el servicio en caso de fallos.

Como resumen visual:

<img src="https://d33wubrfki0l68.cloudfront.net/2475489eaf20163ec0f54ddc1d92aa8d4c87c96b/e7c81/images/docs/components-of-kubernetes.svg" alt="Components of Kubernetes" style="zoom:80%;" />

Para un entendimiento más profundo de los componentes del **control plane**, ver la [documentación oficial](https://kubernetes.io/es/docs/concepts/overview/components/).

### Kubernetes gestionado: Google App Engine (GAE)

Una vez hayamos experimentado un poco con K8s será cuestión de tiempo que lleguemos a la pregunta: ¿Cómo podría deshacerme de tanta gestión (programática) y centrarme en el desarrollo en el caso que mi objetivo central sea el producto? Si revisamos el material que hemos estudiado hasta ahora, la respuesta a tal pregunta tiene una realidad conocida como **PaaS**. En el contexto de GCP, el servicio que nos permite abstraernos de la gestión de la infraestructura y centrarnos en el desarrollo de Apps es conocido como [Google App Engine](https://cloud.google.com/appengine/docs/standard/python3/an-overview-of-app-engine) (GAE).

GAE nos brinda la oportunidad de las bondades de K8s, tales como el autoescalado, sin que tengamos que ser nosotros los que nos preocupemos por gestionar el cluster. Así, GAE se puede entender como un cluster de K8s gestionado automáticamente por Google. Es por ello por lo que todos nuestros esfuerzos se pueden centrar única y exclusivamente en el desarrollo del software (app), dejando la gestión del cluster a Google (sin más que especificar algunas propiedades del cluster para controlar costes, como pueden ser el máximo numero de instancias, etc.)

Podemos entender GAE como el servicio ideal donde desplegar nuestros micro-servicios, los cuales conjuntamente constituyen un ecosistema interconectado, sobre el que podremos ir construyendo capas superiores de abstracción con el fin de acabar con el desarrollo monolítico. 

Una vez tengamos una versión inicial de nuestro aplicativo (app), podremos servirlo inmediatamente en uno de los dos entornos proporcionados por GAE:

* **Standard**: En caso que nuestro aplicativo esté escrito en uno de los siguientes lenguajes y versiones:

  * Python 2.7, Python 3.7, Python 3.8, Python 3.9
  * Java 8, Java 11
  * Node.js 10, Node.js 12, Node.js 14, Node.js 16 (preview)
  * PHP 5.5, PHP 7.2, PHP 7.3, and PHP 7.4
  * Ruby 2.5, Ruby 2.6, and Ruby 2.7
  * Go 1.11, Go 1.12, Go 1.13, Go 1.14, Go 1.15, and Go 1.16 (preview)

  Podremos disfrutar de un entorno "standard", de manera que GAE se encargará de contenerizar nuestro código y desplegarlo en instancias a muy bajo coste. 

* **Flexible**: En el caso que nuestro aplicativo esté contenerizado, y queramos lanzarlo como contenedor porque depende de librerías no estándares, o está escrito en un lenguaje no listado, o tiene unas necesidades computacionales algo más exigentes que las ofertadas en el entorno standard. El entorno de despliegue flexible nos permite una mayor personalización en términos de recursos, lo cual puede ser muy conveniente.

Para un mayor entendimiento de la diferencia entre ambos modelos, podemos ver la [documentación oficial](https://cloud.google.com/appengine/docs/the-appengine-environments).



##### 💻 QuickLab V: Soluciones y estrategias de autoescalado con K8s

* Este lab es uno de los más técnicos que vamos a tener, precisamente para entender la complejidad de K8s, además de la infinidad de configuraciones posibles existentes (a pesar de tan solo explorar una pequeñísima fracción del todo en este ejemplo). En particular, veremos la posibilidad de escalar horizontal y verticalmente a nivel POD, para posteriormente ver cómo este escalamiento horizontal y vertical se puede realizar a nivel cluster. Este nivel de control de un cluster es necesario cuando trabajemos con proyectos productivos, en los que queremos una máxima estabilidad y resiliencia del servicio, pero al menor coste posible (es decir, con la menor cantidad de infraestructura), y a su vez que la infraestructura se adapte automáticamente a los picos de demanda tan característicos del entorno digital de hoy en día. Como se puede desprender del enunciado del objetivo del lab, el problema es algo bastante complicado. El hecho que GKE nos permita esta gestión de manera automática y nos provea con soluciones para gestionar este automatismo es lo que hace que GKE sea el número uno en la gestión de contenedores en entornos cloud. Sin embargo, también vamos a ver con ello el intenso trabajo que esta configuración, mantenimiento y monitorización requiere. Es por ello por lo que el siguiente paso natural es intentar evitar susodicha gestión a menos que sea absolutamente necesaria. Pensando en ello, todos los proveedores cloud a día de hoy proporcionan soluciones de K8s gestionados. En el caso de Google se tratará de Google App Engine (con el que trabajaremos en el siguiente QL). El código y sumario de este QuickLab se puede encontrar en el siguiente: [link](**PENDING**). 



