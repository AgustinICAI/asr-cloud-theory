Conceptos necesarios para entender k8s:

* **Cluster**: Cuando "desplegamos" con k8s, lo que estamos creando/obteniendo es un cluster. Un cluster no es m치s que un conjunto de VMs (nodos) que ejecutan aplicaciones contenerizadas. Todo cluster tiene al menos un nodo.

* **Node**: Como hemos comentado, un nodo es una instancia de una VM donde se sirven los contenedores de nuestras aplicaciones
* **Pod**: Un pod es una abstracci칩n de k8s que representa un conjunto de contenedores que son servidos en un nodo
* **Control plane**: Se refiere a la capa de orquestaci칩n que expone la API e interfaces para definir, desplegar, y gestionar el ciclo de vida de los contenedores. En un entorno productivo, el **control plane** suele estar corriendo en varios nodos, lo que garantiza el servicio en caso de fallos.

Como resumen visual:

<img src="https://d33wubrfki0l68.cloudfront.net/2475489eaf20163ec0f54ddc1d92aa8d4c87c96b/e7c81/images/docs/components-of-kubernetes.svg" alt="Components of Kubernetes" style="zoom:80%;" />

Para un entendimiento m치s profundo de los componentes del **control plane**, ver la [documentaci칩n oficial](https://kubernetes.io/es/docs/concepts/overview/components/).

### Kubernetes gestionado: Google App Engine (GAE)

Una vez hayamos experimentado un poco con K8s ser치 cuesti칩n de tiempo que lleguemos a la pregunta: 쮺칩mo podr칤a deshacerme de tanta gesti칩n (program치tica) y centrarme en el desarrollo en el caso que mi objetivo central sea el producto? Si revisamos el material que hemos estudiado hasta ahora, la respuesta a tal pregunta tiene una realidad conocida como **PaaS**. En el contexto de GCP, el servicio que nos permite abstraernos de la gesti칩n de la infraestructura y centrarnos en el desarrollo de Apps es conocido como [Google App Engine](https://cloud.google.com/appengine/docs/standard/python3/an-overview-of-app-engine) (GAE).

GAE nos brinda la oportunidad de las bondades de K8s, tales como el autoescalado, sin que tengamos que ser nosotros los que nos preocupemos por gestionar el cluster. As칤, GAE se puede entender como un cluster de K8s gestionado autom치ticamente por Google. Es por ello por lo que todos nuestros esfuerzos se pueden centrar 칰nica y exclusivamente en el desarrollo del software (app), dejando la gesti칩n del cluster a Google (sin m치s que especificar algunas propiedades del cluster para controlar costes, como pueden ser el m치ximo numero de instancias, etc.)

Podemos entender GAE como el servicio ideal donde desplegar nuestros micro-servicios, los cuales conjuntamente constituyen un ecosistema interconectado, sobre el que podremos ir construyendo capas superiores de abstracci칩n con el fin de acabar con el desarrollo monol칤tico. 

Una vez tengamos una versi칩n inicial de nuestro aplicativo (app), podremos servirlo inmediatamente en uno de los dos entornos proporcionados por GAE:

* **Standard**: En caso que nuestro aplicativo est칠 escrito en uno de los siguientes lenguajes y versiones:

  * Python 2.7, Python 3.7, Python 3.8, Python 3.9
  * Java 8, Java 11
  * Node.js 10, Node.js 12, Node.js 14, Node.js 16 (preview)
  * PHP 5.5, PHP 7.2, PHP 7.3, and PHP 7.4
  * Ruby 2.5, Ruby 2.6, and Ruby 2.7
  * Go 1.11, Go 1.12, Go 1.13, Go 1.14, Go 1.15, and Go 1.16 (preview)

  Podremos disfrutar de un entorno "standard", de manera que GAE se encargar치 de contenerizar nuestro c칩digo y desplegarlo en instancias a muy bajo coste. 

* **Flexible**: En el caso que nuestro aplicativo est칠 contenerizado, y queramos lanzarlo como contenedor porque depende de librer칤as no est치ndares, o est치 escrito en un lenguaje no listado, o tiene unas necesidades computacionales algo m치s exigentes que las ofertadas en el entorno standard. El entorno de despliegue flexible nos permite una mayor personalizaci칩n en t칠rminos de recursos, lo cual puede ser muy conveniente.

Para un mayor entendimiento de la diferencia entre ambos modelos, podemos ver la [documentaci칩n oficial](https://cloud.google.com/appengine/docs/the-appengine-environments).



##### 游눹 QuickLab V: Soluciones y estrategias de autoescalado con K8s

* Este lab es uno de los m치s t칠cnicos que vamos a tener, precisamente para entender la complejidad de K8s, adem치s de la infinidad de configuraciones posibles existentes (a pesar de tan solo explorar una peque침칤sima fracci칩n del todo en este ejemplo). En particular, veremos la posibilidad de escalar horizontal y verticalmente a nivel POD, para posteriormente ver c칩mo este escalamiento horizontal y vertical se puede realizar a nivel cluster. Este nivel de control de un cluster es necesario cuando trabajemos con proyectos productivos, en los que queremos una m치xima estabilidad y resiliencia del servicio, pero al menor coste posible (es decir, con la menor cantidad de infraestructura), y a su vez que la infraestructura se adapte autom치ticamente a los picos de demanda tan caracter칤sticos del entorno digital de hoy en d칤a. Como se puede desprender del enunciado del objetivo del lab, el problema es algo bastante complicado. El hecho que GKE nos permita esta gesti칩n de manera autom치tica y nos provea con soluciones para gestionar este automatismo es lo que hace que GKE sea el n칰mero uno en la gesti칩n de contenedores en entornos cloud. Sin embargo, tambi칠n vamos a ver con ello el intenso trabajo que esta configuraci칩n, mantenimiento y monitorizaci칩n requiere. Es por ello por lo que el siguiente paso natural es intentar evitar susodicha gesti칩n a menos que sea absolutamente necesaria. Pensando en ello, todos los proveedores cloud a d칤a de hoy proporcionan soluciones de K8s gestionados. En el caso de Google se tratar치 de Google App Engine (con el que trabajaremos en el siguiente QL). El c칩digo y sumario de este QuickLab se puede encontrar en el siguiente: [link](**PENDING**). 



