# 3. Cloud Computing

### 3.5 Dise√±o y despliegue de aplicaciones nativas Cloud

Ahora que tenemos un buen conocimiento de lo que nos oferta una nube (bien sea p√∫blica o privada), vamos a proceder con un salto gradual desde el desarrollo local (t√≠picamente monol√≠tico) hasta el desarrollo nativo en nube (*cloud native*) en el que se aprovechar√°n todo el potencial ofertado por el *cloud computing*.

#### Aplicaciones nativas Cloud (Cloud native applications): Introducci√≥n

El concepto del desarrollo de **aplicaciones nativas cloud** hace referencia a un paradigma de desarrollo de software que utiliza el entorno cloud para crear y desplegar aplicaciones en infraestructuras din√°micas y flexibles, como es el caso de la nube. 

Este paradigma de desarrollo suele ir acompa√±ado del uso de las siguientes tecnolog√≠as:

* Plataformas cloud
* Metodolog√≠as √°giles ([Agile software development](https://en.wikipedia.org/wiki/Agile_software_development))
* Contenerizaci√≥n y [microservicios](https://en.wikipedia.org/wiki/Microservices)
* Orquestaci√≥n de contenedores ([Docker Compose](https://docs.docker.com/compose/) y [Kubernetes](https://en.wikipedia.org/wiki/Kubernetes) [k8s])
* Funciones (FaaS) y plataformas *serverless* ([Serverless computing](https://en.wikipedia.org/wiki/Serverless_computing))
* Integraci√≥n continua y Entrega continua ([Continuos Integration and Continuos Delivery](https://en.wikipedia.org/wiki/CI/CD) [CI/CD])

<img src="/Users/mduranol/Dropbox/Root/Home/Documents/ICAI/course-2021/teaching/ASR/theory/images/cloud-native.png" alt="cloud-native" style="zoom:67%;" />



#### Contenerizaci√≥n y microservicios

Uno de las caracter√≠sticas fundamentales que diferencia una aplicaci√≥n nativa cloud de una aplicaci√≥n tradicional es precisamente la contenerizaci√≥n y su infraestructura de microservicios.

De la contenerizaci√≥n ya hemos hablado extendidamente en el cap√≠tulo anterior cuando tratamos la virtualizaci√≥n de sistemas operativos, tanto de ventajas como desventajas. Sin embargo, es bueno que subrayemos la importancia de dicha tecnolog√≠a en lo que a la **reproducibilidad** se refiere. El contenerizar una aplicaci√≥n con todas las dependencias requeridas ha revolucionado por completo el paradigma del desarrollo en servidores. Previamente a la contenerizaci√≥n, la estabilizaci√≥n de entornos de desarrollo pod√≠a llegar a ser algo bastante tedioso, incluso convertirse en un problema a la hora del poder desarrollar, llegando en los casos m√°s extremos a  convertirse en un factor de entorpecimiento a la hora de llevar a producci√≥n nuevos desarrollos, por no ser compatibles estos con las dependencias instaladas en el entorno productivo, sobre todo en proyectos de larga envergadura. La contenerizaci√≥n ataca una de las caras de este problema y es el aislamiento de dependencias de una aplicaci√≥n, lo cual hace posible que su desarrollo sea completamente reproducible en cualquier entorno de trabajo, bien sea testing, desarrollo o productivo.

La arquitectura basada en microservicios constituye otro cambio de paradigma en el desarrollo de software, y consiste en construir una aplicaci√≥n como un conjunto de peque√±os [servicios](https://es.wikipedia.org/wiki/Servicio_(arquitectura_de_sistemas)), los cuales se ejecutan en su propio [proceso](https://es.wikipedia.org/wiki/Proceso_(inform√°tica)) y se comunican con mecanismos ligeros (normalmente una [API](https://es.wikipedia.org/wiki/Interfaz_de_programaci√≥n_de_aplicaciones) de [recursos HTTP](https://es.wikipedia.org/wiki/Hypertext_Transfer_Protocol)). Cada "micro"-servicio se encarga de implementar una funcionalidad completa de negocio, de manera independiente y completamente aut√≥noma. As√≠, cada micro-servicio puede ser desplegado de forma independiente y puede estar programado en distintos lenguajes y usar diferentes tecnolog√≠as de almacenamiento de datos. Esta filosof√≠a de desarrollo evidentemente rompe con la filosof√≠a tradicional monol√≠tica, orientada a poyectos, que no a funcionalidades. La filosof√≠a monol√≠tica conlleva una serie de restricciones bastante importantes a la hora del desarrollo, como es por ejemplo el hecho de forzar un √∫nico lenguaje de programaci√≥n o compatibilidad de librer√≠as para todo un proyecto, lo cu√°l se convierte en algo m√°s y m√°s complicado a medida que un proyecto crece en complejidad (lo cu√°l es natural en la vida real). Por contra, los microservicios proponen como soluci√≥n que cada funcionalidad de un proyecto ha de ser identificada y aislada como un proceso/servicio independiente, atendiendo al principio de √∫nica responsabilidad (*single-responsibility principle*). Esto ayuda de antemano a desacoplar las diferentes unidades de un proyecto, lo que a su vez es m√°s beneficioso a la hora de renovar, refactorizar o reinventar partes del mismo, sin tener que atender a m√°s preocupaci√≥n que la interfaz program√°tica de comunicaci√≥n (API).

| Ventajas                                                     | Inconvenientes                                        |
| ------------------------------------------------------------ | ----------------------------------------------------- |
| Incrementa la eficiencia: divide la funcionalidad, mejora la escalabilidad | Latencia de red                                       |
| Facilita las actualizaciones                                 | Complejidad del dise√±o                                |
| Mejora la estabilidad                                        | ¬øQu√© es un microservicio? Tama√±o, funcionalidad, etc. |
| Desacoplado de recursos f√≠sicos                              | Estandarizaci√≥n de interfaces                         |
| Multi-idioma/plataforma/‚Ä¶                                    |                                                       |
| F√°cil de construir/probar/desplegar                          |                                                       |

 A continuaci√≥n se muestra una figura en la que se comparan de manera esquem√°tica las arquitecturas tradicionales *versus* las arquitecturas orientadas a microservicios.![soa-vs-microservices](/Users/mduranol/Dropbox/Root/Home/Documents/ICAI/course-2021/teaching/ASR/theory/images/soa-vs-microservices.png)



#### Orquestaci√≥n de contenedores: Kubernetes

Si prestamos suficiente atenci√≥n a nuestro QuickLab (QL) I veremos que lo que realmente hemos hecho es preparar dos microservicios (cada uno con una responsabilidad √∫nica y bien definida, ver [*Single Responsibility Principle*](https://en.wikipedia.org/wiki/Single-responsibility_principle)) que posteriormente hemos desplegado en GCP. Cuando llegamos a este punto en el cap√≠tulo de virtualizaci√≥n vimos que ***en local*** pod√≠amos "orquestar" (gestionar de manera conjunta y organizada un conjunto de) contenedores mediante el uso de [Docker Compose](https://docs.docker.com/compose/). Para ello se usaba **docker compose engine**, un comando de terminal que en √∫ltima instancia depend√≠a de un fichero (manifiesto) de configuraci√≥n que se sol√≠a llamar `docker-compose.yaml` donde especific√°bamos los contenedores a crear/lanzar, sus configuraciones de red/puertos, adem√°s de su vol√∫menes etc. Un ejemplo sencillo era:

```yaml
version: "3.9"
services:
  web:
    build: .
    ports:
      - "5000:5000"
  redis:
    image: "redis:alpine"	
```

Que posteriormente us√°bamos mediante:

```shell
$ docker-compose up
```

lo cual pon√≠a en marcha una API (que se especificaba en el Dockerfile que constru√≠amos como `web`) que permit√≠a insertar registros en una base de datos [`redis`](https://redis.io/), y que posteriormente pod√≠amos parar con una simple l√≠nea de comandos:

```bash
$ docker-compose stop
```

Inmediatamente vimos la conveniencia y eficiencia que `docker-compose` tra√≠a a nuestro ecosistema de desarrollo. Pero, tambi√©n vimos una *peque√±a* inconveniencia, que de hecho no es tan peque√±a en el caso que nuestro objetivos se el disponer de una arquitectura flexible, din√°mica y f√°cilmente gestionable. Con `docker-compose`  gestionamos contenedores, pero todos los servicios conviven en el mismo host. La pregunta natural entonces es, ¬øC√≥mo podr√≠amos hacer que cada contenedor sea desplegado en un host distinto y de forma que pueda ser autoescalado independiente? 

Para este problema de orquestaci√≥n de contenedores y arquitectura asociada existen principalmente dos soluciones: `docker swarm` y `kubernetes engine`. Aunque ambos dos proponen una soluci√≥n a un mismo problema, existen peque√±as diferencias que hacen que Kubernetes haya sido el m√°s usado en la industria. Muy resumidamente:

- [Docker swarm](https://docs.docker.com/engine/swarm/): es una herramienta de orquestaci√≥n de contenedores, la cual nos permite llegar a la soluci√≥n deseada de lanzar im√°genes en diferentes m√°quinas (hosts) 
- [Kubernetes](https://kubernetes.io/): es una herramienta de orquestaci√≥n de contenedores, que como en el caso de docker swarm nos permite el lanzamiento de im√°genes en diferentes hosts, pero su *focus* principal ha sido la automatizaci√≥n y habilidad de adaptarse a escenarios de alta demanda 

As√≠ pues, se puede decir que la mayor diferencia entre Docker swarm y Kubernetes es la facilidad de uso. Nada ilustra mejor esto que un ejemplo sobre c√≥mo cada uno maneja las redes. Cuando se crea un cl√∫ster de contenedores con Docker swarm, esos contenedores generalmente est√°n disponibles en nuestra red porque ha dirigido un puerto externo a un puerto interno desde el comando `docker`. En otras palabras, no tenemos que configurar una capa de red separada dentro de los archivos YAML. Sin embargo, con Kubernetes, debemos configurar una capa de red (utilizando declaraciones como `hostNetwork: true` dentro del manifiesto correspondiente). Si no agregamos esta capa de red accesible a la `LAN` dentro de los archivos YAML, no podremos acceder a los contenedores desde cualquier lugar que no sea el cl√∫ster de Kubernetes. A pesar que puede parecer que esto a√±ade trabajo a la persona encargada, la realidad es que esto tambi√©n trae con ello un incremento grand√≠simo de la reproducibilidad del comportamiento, lo que nos puede salvar bastantes horas de debugging.

As√≠ pues, Docker Swarm es mucho m√°s sencillo en t√©rminos de uso y exploraci√≥n, pero Kubernetes es mucho m√°s escalable. Entonces, ¬øcuando deber√≠amos usar uno u otro?

* **Docker Swarm**: Cuando queremos implementar un cluster de contenedores (en varios hosts) para una aplicaci√≥n simple y escalable
* **Kubernetes**: Cuando queremos administrar una aplicaci√≥n de microservicios contenerizados, escalables y automatizados.

Es por esto mismo por lo que los principales proveedores de cloud ofertan directamente Kubernetes. En el caso de Google, Kubernetes se oferta parte de los servicios que podemos usar en la modalidad "pay as you go" y se denomina [**Google Kubernetes Engine**](https://cloud.google.com/kubernetes-engine/docs/quickstart) (GKE).

K8s conlleva una curva de aprendizaje, no cabe ninguna duda. Y por ello, no pretendemos dar un (mini-)curso, sino algunos conceptos b√°sicos y necesarios para introducir esta herramienta de incre√≠ble alcance de la que se podr√≠a dar un curso completo para su total entendimiento. Finalmente veremos, como viene siendo costumbre, un ejemplo pr√°ctico con nuestro QL III.

Conceptos necesarios para entender k8s:

* **Cluster**: Cuando "desplegamos" con k8s, lo que estamos creando/obteniendo es un cluster. Un cluster no es m√°s que un conjunto de VMs (nodos) que ejecutan aplicaciones contenerizadas. Todo cluster tiene al menos un nodo.

* **Node**: Como hemos comentado, un nodo es una instancia de una VM donde se sirven los contenedores de nuestras aplicaciones
* **Pod**: Un pod es una abstracci√≥n de k8s que representa un conjunto de contenedores que son servidos en un nodo
* **Control plane**: Se refiere a la capa de orquestaci√≥n que expone la API e interfaces para definir, desplegar, y gestionar el ciclo de vida de los contenedores. En un entorno productivo, el **control plane** suele estar corriendo en varios nodos, lo que garantiza el servicio en caso de fallos.

Como resumen visual:

<img src="https://d33wubrfki0l68.cloudfront.net/2475489eaf20163ec0f54ddc1d92aa8d4c87c96b/e7c81/images/docs/components-of-kubernetes.svg" alt="Components of Kubernetes" style="zoom:80%;" />

Para un entendimiento m√°s profundo de los componentes del **control plane**, ver la [documentaci√≥n oficial](https://kubernetes.io/es/docs/concepts/overview/components/).

#### Kubernetes gestionado: Google App Engine (GAE)

Una vez hayamos experimentado un poco con K8s (e.g. haciendo los QLs III y IV) ser√° cuesti√≥n de tiempo que lleguemos a la pregunta: ¬øC√≥mo podr√≠a deshacerme de tanta gesti√≥n (program√°tica) y centrarme en el desarrollo en el caso que mi objetivo central sea el producto? Si revisamos el material que hemos estudiado hasta ahora, la respuesta a tal pregunta tiene una realidad conocida como **PaaS**. En el contexto de GCP, el servicio que nos permite abstraernos de la gesti√≥n de la infraestructura y centrarnos en el desarrollo de Apps es conocido como [Google App Engine](https://cloud.google.com/appengine/docs/standard/python3/an-overview-of-app-engine) (GAE).

GAE nos brinda la oportunidad de las bondades de K8s, tales como el autoescalado, sin que tengamos que ser nosotros los que nos preocupemos por gestionar el cluster. As√≠, GAE se puede entender como un cluster de K8s gestionado autom√°ticamente por Google. Es por ello por lo que todos nuestros esfuerzos se pueden centrar √∫nica y exclusivamente en el desarrollo del software (app), dejando la gesti√≥n del cluster a Google (sin m√°s que especificar algunas propiedades del cluster para controlar costes, como pueden ser el m√°ximo numero de instancias, etc.)

Podemos entender GAE como el servicio ideal donde desplegar nuestros micro-servicios, los cuales conjuntamente constituyen un ecosistema interconectado, sobre el que podremos ir construyendo capas superiores de abstracci√≥n con el fin de acabar con el desarrollo monol√≠tico. 

Una vez tengamos una versi√≥n inicial de nuestro aplicativo (app), podremos servirlo inmediatamente en uno de los dos entornos proporcionados por GAE:

* **Standard**: En caso que nuestro aplicativo est√© escrito en uno de los siguientes lenguajes y versiones:

  * Python 2.7, Python 3.7, Python 3.8, Python 3.9
  * Java 8, Java 11
  * Node.js 10, Node.js 12, Node.js 14, Node.js 16 (preview)
  * PHP 5.5, PHP 7.2, PHP 7.3, and PHP 7.4
  * Ruby 2.5, Ruby 2.6, and Ruby 2.7
  * Go 1.11, Go 1.12, Go 1.13, Go 1.14, Go 1.15, and Go 1.16 (preview)

  Podremos disfrutar de un entorno "standard", de manera que GAE se encargar√° de contenerizar nuestro c√≥digo y desplegarlo en instancias a muy bajo coste. 

* **Flexible**: En el caso que nuestro aplicativo est√© contenerizado, y queramos lanzarlo como contenedor porque depende de librer√≠as no est√°ndares, o est√° escrito en un lenguaje no listado, o tiene unas necesidades computacionales algo m√°s exigentes que las ofertadas en el entorno standard. El entorno de despliegue flexible nos permite una mayor personalizaci√≥n en t√©rminos de recursos, lo cual puede ser muy conveniente.

Para un mayor entendimiento de la diferencia entre ambos modelos, podemos ver la [documentaci√≥n oficial](https://cloud.google.com/appengine/docs/the-appengine-environments).

#### Aplicaciones Serverless: El esp√≠ritu cloud native

Finalmente, incluso deshaci√©ndonos de la responsabilidad de mantener el cluster de K8s mediante el uso de GAE, tenemos una limitaci√≥n y es que seguimos teniendo que mantener un m√≠nimo de 1 instancia (nodo) funcionando 24/7. Sin embargo, nuestro objetivo √∫ltimo siempre ha sido el llegar a una arquitectura que sea lo m√°s din√°mica posible, con la idea en mente de escalar hasta cero instancias si fuera posible, de manera que solo pag√°semos realmente por aquello que usamos. Y este es precisamente el objetivo de las dos √∫ltimos servicios de hosting de aplicativos que vamos a ver, que son:

* Cloud Functions
* Cloud Run

Ambos dos se centran en el concepto de escalar a cero, es decir, de deshacernos del concepto de "servidor" (*serverless*) mediante la gesti√≥n activa y autom√°tica de infraestructura y plataforma de Google. Como veremos ambos est√°n √≠ntimamente relacionados entre s√≠, y su diferencia tiene que ver con los environments standard y flexible de GAE.

Este paradigma de desarrollo se conoce como **Funtions as a Service** (FaaS), dado que el objetivo principal es la programaci√≥n de una funcionalidad (que en √∫ltima instancia se entiende que se ejecutar√° en reacci√≥n a un evento dado). El esquema IaaS, PaaS y SaaS que vimos anteriormente queda ampliado del siguiente modo:

<img src="https://miro.medium.com/max/1145/1*DYoadhgfpZCMRCMKNUpQ6A.png" alt="What are Cloud Computing Services [IaaS, CaaS, PaaS, FaaS, SaaS] | by  Nilesh Suryavanshi | Medium" style="zoom:67%;" />

De modo que en una arquitectura FaaS (serverless) lo √∫nico de lo que tenemos que hacernos cargo es de la gesti√≥n de los datos procesados o generados por la "funci√≥n".

Las ventajas principales son:

* No tendr√°s que aprovisionar, administrar ni actualizar servidores
* Escala autom√°ticamente seg√∫n la carga. Se paga por el tiempo de procesamiento de la funci√≥n
* Funciones integradas de supervisi√≥n, registro y depuraci√≥n 
* Seguridad integrada a nivel de funciones y por funci√≥n que se basa en el principio de privilegio m√≠nimo
* Capacidades de red clave para situaciones h√≠bridas y de m√∫ltiples nubes

##### Functions as a Service (FaaS): Google Cloud Functions

Cloud functions nos brinda la oportunidad √∫nica de ir directamente de c√≥digo a aplicativo serverless sin necesidad de contenerizaci√≥n.

**Serverless Apps**: **Google Cloud Run**

Cloud run se puede entender como el paso intermedio entre GCF y GAE, i.e., con GCR podremos montar un aplicativo serverless cuando nuestro aplicativo ya est√© contenerizado.

#### Los 12 factores

‚ÄúTwelve-factor app‚Äù es una metodolog√≠a para el desarrollo de aplicaciones nativas en la nube cuyas caracter√≠sticas esenciales son: 

- Formatos declarativos para la automatizaci√≥n de la configuraci√≥n
- M√°xima portabilidad entre los diferentes entornos de ejecuci√≥n
- Despliegue en la nube, por lo que se obviar√° la necesidad de servidores y administraci√≥n de sistemas
- Minimizan las diferencias entre los entornos de desarrollo y producci√≥n
- Posibilidad de escalado

Los 12 factores son: 

1. **Codebase**: Un c√≥digo base sobre el que hacer el control de versiones y m√∫ltiples despliegues. 
2. **Dependencies**: Declarar y aislar expl√≠citamente las dependencias mediante un manifiesto. Nunca depender√° de las librer√≠as ya instaladas en el sistema por defecto
3. **Config**: Guardar la configuraci√≥n en el entorno que pueda variar entre despliegues (producci√≥n o desarrollo, por ejemplo)
4. **Backing services**: Tratar a los ‚Äúbacking services‚Äù como recursos conectables
5. **Build, release, run**: Separar completamente la etapa de construcci√≥n de la etapa de ejecuci√≥n
6. **Processes**: Ejecutar la aplicaci√≥n como uno o m√°s procesos sin estado. Los procesos deben ser stateless y share-nothing. Cualquier informaci√≥n que necesite persistencia se debe almacenar en un backing service con estado (e.g., una base de datos). 
7. **Port binding**: En entornos locales un servicio como un servidor web inicia en un puerto para todas las apps. En 12-factor apps, una capa de enrutamiento se encargar√° de gestionar los puertos de cada servicio
8. **Concurrency**: Escalar mediante el modelo de procesos
9. **Disposability**: Hacer el sistema m√°s robusto intentando conseguir inicios r√°pidos y finalizaciones seguras. Las 12- factor apps deber√°n ser plenamente desechables en cualquier momento. 
10. **Dev/prod parity**: Mantener desarrollo, preproducci√≥n y producci√≥n tan parecidos como sea posible 
11. **Logs**: Tratar los historiales como una transmisi√≥n de eventos. 
12. **Admin processes**: Ejecutar las tareas de gesti√≥n/administraci√≥n como procesos que solo se ejecutan una vez. 

‚Äú[Twelvefactor](https://12factor.net/)‚Äù recomienda lenguajes que proporcionan una consola del tipo REPL, ya que facilitan las tareas relacionadas con la ejecuci√≥n de scripts

#### QuickLabs

Para reforzar los conceptos que vamos introduciendo de manera te√≥rica hemos dise√±ado varios ejemplos en los que iremos trabajando con la nube de Google (GCP). En este momento, tras haber introducido las ventajas e inconvenientes de la contenerizaci√≥n y los microservicios, es interesante que procedamos con los siguientes ejemplos:

##### üíª QuickLab I: Creaci√≥n y despliegue de contenedores en GCP

* Creaci√≥n y despliegue de un microservicio con Flask que nos permite la inserci√≥n y borrado de registros mediante una API sencilla en una base de datos *in-memory* (redis). El objetivo de este ejemplo es el de mostrar la estructura t√≠pica de una aplicaci√≥n con varios microservicios, y la gesti√≥n de su despliegue de manera program√°tica (pero a√∫n manual) en la nube mediate Google SDK. El c√≥digo y sumario de este QuickLab pueden encontrarse en este [link]( https://github.com/**PENDING**/asr-cloud/tree/main/03-flask-redis).   

##### üíª QuickLab II: SuperMario auto-escalable

* Creaci√≥n y despliegue de una aplicaci√≥n dada (como Docker Image) con autoescalado y balanceado de carga. El objetivo es ir un paso m√°s all√° del ejemplo anterior, y mostrar lo conveniente que es la contenerizaci√≥n de aplicaciones para su despliegue en una infraestructura autoescalable seg√∫n la utilizaci√≥n del servicio. Para ello tendremos que crear un grupo de instancias gestionadas que se desplieguen con la imagen de la aplicaci√≥n en el arranque, y que autoescalen a medida que sea necesario acorde a un umbral de utilizaci√≥n. Para servir la aplicaci√≥n con una √∫nica IP a nuestros pot√©nciales clientes, tendremos que crear un balanceado de carga (con *Cloud Load Balancer*) que har√° la el enrutamiento correcto a la VM adecuada. El c√≥digo y sumario de este QuickLab se puede encontrar en el siguiente: [link](https://github.com/**PENDING**/asr-cloud/tree/main/04-autoscaling-mario). 

##### üíª QuickLab III: SuperMario con K8s

* El objetivo es ir un paso m√°s all√° del ejemplo anterior, y mostrar lo conveniente que es la utilizaci√≥n de GKE. Para ello tendremos que crear un cluster de K8s en GCP. El c√≥digo y sumario de este QuickLab se puede encontrar en el siguiente: [link](https://github.com/**PENDING**/asr-cloud/tree/main/05-k8s-init). 

##### üíª QuickLab IV: Soluciones y estrategias de autoescalado con K8s

* Este lab es uno de los m√°s t√©cnicos que vamos a tener, precisamente para entender la complejidad de K8s, adem√°s de la infinidad de configuraciones posibles existentes (a pesar de tan solo explorar una peque√±√≠sima fracci√≥n del todo en este ejemplo). En particular, veremos la posibilidad de escalar horizontal y verticalmente a nivel POD, para posteriormente ver c√≥mo este escalamiento horizontal y vertical se puede realizar a nivel cluster. Este nivel de control de un cluster es necesario cuando trabajemos con proyectos productivos, en los que queremos una m√°xima estabilidad y resiliencia del servicio, pero al menor coste posible (es decir, con la menor cantidad de infraestructura), y a su vez que la infraestructura se adapte autom√°ticamente a los picos de demanda tan caracter√≠sticos del entorno digital de hoy en d√≠a. Como se puede desprender del enunciado del objetivo del lab, el problema es algo bastante complicado. El hecho que GKE nos permita esta gesti√≥n de manera autom√°tica y nos provea con soluciones para gestionar este automatismo es lo que hace que GKE sea el n√∫mero uno en la gesti√≥n de contenedores en entornos cloud. Sin embargo, tambi√©n vamos a ver con ello el intenso trabajo que esta configuraci√≥n, mantenimiento y monitorizaci√≥n requiere. Es por ello por lo que el siguiente paso natural es intentar evitar susodicha gesti√≥n a menos que sea absolutamente necesaria. Pensando en ello, todos los proveedores cloud a d√≠a de hoy proporcionan soluciones de K8s gestionados. En el caso de Google se tratar√° de Google App Engine (con el que trabajaremos en el siguiente QL). El c√≥digo y sumario de este QuickLab se puede encontrar en el siguiente: [link](**PENDING**). 

üíª **QuickLab V: App Engine**

* En este lab el objetivo es demostrar la sencillez del despliegue y mantenimiento de una App que se despliega en [Google App Engine](https://cloud.google.com/appengine/docs) (GAE). Para ello, vamos a desplegar un Super Mario auto-escalable, con un simple comando, y sin necesidad de tener que gestionar nosotros el tipo de escalado. GAE nos ofrece autom√°ticamente la posibilidad de un auto-escalado (horizontal) autom√°tico, adem√°s de una gesti√≥n del balanceamiento de carga autom√°tico. El c√≥digo y sumario de este QuickLab se puede encontrar en el siguiente: [link](https://github.com/**PENDING**/asr-cloud/tree/main/07-gae-example).

üíª **QuickLab VI: Cloud Functions**

* El objetivo de este lab es la demostraci√≥n de como podemos desplegar de manera sencilla una funci√≥n en Google Cloud Function. Para este prop√≥sito hemos creado una funci√≥n en Python cuyo "trigger" es una llamada HTTP. El c√≥digo y sumario de este QuickLab se puede encontrar en el siguiente: [link](https://github.com/**PENDING**/asr-cloud/tree/main/08-cloud-functions).

üíª **QuickLab VI: Cloud Run**

* Tal y como hemos comentado en clase, existe una segunda opci√≥n para desplegar apps serverless, que tiene la conveniencia de aceptar **Docker Images** en lugar de **Functions**. Esta opci√≥n en GCP se llama Google Cloud Run. En este lab ponemos de manifiesto la sencillez y conveniencia del uso de GCR (documentaci√≥n oficial [aqu√≠](https://cloud.google.com/run)). El c√≥digo y sumario de este QuickLab se puede encontrar en el siguiente: [link](https://github.com/**PENDING**/asr-cloud/tree/main/09-cloudrun). En este lab se muestran tambi√©n opciones de gesti√≥n program√°tica y de CICD.

